{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vanessa Williams\n",
        "# Milestone 3"
      ],
      "metadata": {
        "id": "JQ-chEJ6Tw72"
      },
      "id": "JQ-chEJ6Tw72"
    },
    {
      "cell_type": "markdown",
      "id": "500dca66",
      "metadata": {
        "id": "500dca66"
      },
      "source": [
        "### Load the dataset, Import necessary libraries, and inspect the initial rows to understand the structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828f1fd0",
      "metadata": {
        "id": "828f1fd0",
        "outputId": "f7884b5c-dbdb-4c82-890c-37c0bc715869"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/reneulloa/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.corpus import stopwords\n",
        "import ssl\n",
        "\n",
        "# Bypass SSL verification to download stopwords\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load your dataset\n",
        "file_path = '/Users/vanessawilliams/Desktop/Vanessa_Williams/corpus.csv'\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bce8011",
      "metadata": {
        "id": "0bce8011"
      },
      "source": [
        "### Preprocessing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a3873a",
      "metadata": {
        "id": "e1a3873a"
      },
      "outputs": [],
      "source": [
        "# Sample a smaller portion of the dataset for testing (e.g., 500 rows)\n",
        "sampled_data = data.sample(n=500, random_state=42)\n",
        "\n",
        "# Define a function to clean the text\n",
        "def clean_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Remove non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7a2fa6",
      "metadata": {
        "id": "ac7a2fa6",
        "outputId": "93a329a9-dc3f-41af-bfdd-b4a700396e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                     text   \n",
            "147298  Le président du conseil italien Enrico Letta, ...  \\\n",
            "264296  Une nouvelle fois, la Cour des comptes, dans s...   \n",
            "328459  « Les collectivités locales ont en effet calcu...   \n",
            "13102   La nouvelle loi sur l'immigration dans l'Arizo...   \n",
            "355422  Editorial du « Monde ». Olivier Dussopt va ent...   \n",
            "\n",
            "                                             cleaned_text  \n",
            "147298  le prsident du conseil italien enrico letta le...  \n",
            "264296  une nouvelle fois la cour des comptes dans son...  \n",
            "328459  les collectivits locales ont en effet calcul l...  \n",
            "13102   la nouvelle loi sur limmigration dans larizona...  \n",
            "355422  editorial du monde olivier dussopt va entrepre...  \n"
          ]
        }
      ],
      "source": [
        "# Apply the cleaning function to the text column\n",
        "sampled_data['cleaned_text'] = sampled_data['text'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "# Display the cleaned text\n",
        "print(sampled_data[['text', 'cleaned_text']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4650e7",
      "metadata": {
        "id": "9a4650e7"
      },
      "source": [
        "### Feature Extraction using TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12bbeb14",
      "metadata": {
        "id": "12bbeb14",
        "outputId": "8987169d-2b59-498b-caaf-0bca91509a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Feature Matrix shape: (500, 500)\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(sampled_data['cleaned_text'])\n",
        "\n",
        "# Display the TF-IDF feature matrix\n",
        "print(\"TF-IDF Feature Matrix shape:\", tfidf_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13e141db",
      "metadata": {
        "id": "13e141db"
      },
      "source": [
        "### Latent Dirichlet Allocation (LDA) for Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f40a6f8",
      "metadata": {
        "id": "8f40a6f8",
        "outputId": "4206916c-cd35-42b3-f931-31a9e25ed6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Topics shape: (500, 5)\n"
          ]
        }
      ],
      "source": [
        "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda_topics = lda_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Display the LDA Topics\n",
        "print(\"LDA Topics shape:\", lda_topics.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d403c422",
      "metadata": {
        "id": "d403c422"
      },
      "source": [
        "### Clustering using KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1326f2a",
      "metadata": {
        "id": "c1326f2a",
        "outputId": "94bfd142-2e74-4d32-c6a8-db3e762134a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KMeans Cluster assignments:\n",
            "                                              cleaned_text  cluster\n",
            "147298  le prsident du conseil italien enrico letta le...        3\n",
            "264296  une nouvelle fois la cour des comptes dans son...        3\n",
            "328459  les collectivits locales ont en effet calcul l...        3\n",
            "13102   la nouvelle loi sur limmigration dans larizona...        3\n",
            "355422  editorial du monde olivier dussopt va entrepre...        3\n"
          ]
        }
      ],
      "source": [
        "kmeans_model = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans_clusters = kmeans_model.fit_predict(tfidf_matrix)\n",
        "\n",
        "# Display the cluster assignments\n",
        "sampled_data['cluster'] = kmeans_clusters\n",
        "print(\"KMeans Cluster assignments:\\n\", sampled_data[['cleaned_text', 'cluster']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77aca62",
      "metadata": {
        "id": "c77aca62"
      },
      "source": [
        "### Analyzing each cluster's common terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772cadab",
      "metadata": {
        "id": "772cadab",
        "outputId": "371dca5a-4f47-4ea7-8652-bd2d5f9a145f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top terms in Cluster 0:\n",
            "des\n",
            "comment\n",
            "scne\n",
            "femmes\n",
            "lhistoire\n",
            "conomique\n",
            "mondiale\n",
            "la\n",
            "guerre\n",
            "pourquoi\n",
            "\n",
            "Top terms in Cluster 1:\n",
            "que\n",
            "pas\n",
            "du\n",
            "je\n",
            "en\n",
            "des\n",
            "les\n",
            "et\n",
            "la\n",
            "le\n",
            "\n",
            "Top terms in Cluster 2:\n",
            "trois\n",
            "police\n",
            "dfense\n",
            "femmes\n",
            "cinma\n",
            "la\n",
            "nos\n",
            "abonns\n",
            "article\n",
            "rserv\n",
            "\n",
            "Top terms in Cluster 3:\n",
            "une\n",
            "pour\n",
            "dans\n",
            "du\n",
            "en\n",
            "et\n",
            "des\n",
            "le\n",
            "les\n",
            "la\n",
            "\n",
            "Top terms in Cluster 4:\n",
            "dans\n",
            "une\n",
            "qui\n",
            "des\n",
            "du\n",
            "les\n",
            "en\n",
            "et\n",
            "le\n",
            "la\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"\\nTop terms in Cluster {i}:\")\n",
        "    top_terms_idx = kmeans_model.cluster_centers_.argsort()[:, -10:]\n",
        "    for idx in top_terms_idx[i]:\n",
        "        print(tfidf_vectorizer.get_feature_names_out()[idx])\n",
        "\n",
        "# Save the result for later analysis\n",
        "sampled_data.to_csv('/Users/vanessawilliams/Desktop/Vanessa_Williams/sample_processed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c3a7ae",
      "metadata": {
        "id": "84c3a7ae"
      },
      "source": [
        "### Text Data Processing and Feature Engineering Summary\n",
        "\n",
        "#### 1. **Data Sampling and Preprocessing**:\n",
        "   - We started by loading a large dataset containing text. Due to the dataset's size, we sampled 500 rows to ensure that processing would be more efficient.\n",
        "   - We applied text cleaning steps where we:\n",
        "     - Removed non-alphabetic characters.\n",
        "     - Converted all text to lowercase.\n",
        "     - Removed common stopwords using NLTK's stopword list.\n",
        "\n",
        "#### 2. **TF-IDF (Term Frequency-Inverse Document Frequency) Feature Extraction**:\n",
        "   - We transformed the cleaned text using the TF-IDF technique, which assigns a weight to each word based on how frequently it appears in individual documents compared to the entire corpus.\n",
        "   - The resulting matrix had each document represented by a feature vector of word frequencies, capturing the most important words for each document.\n",
        "\n",
        "#### 3. **Topic Modeling using LDA (Latent Dirichlet Allocation)**:\n",
        "   - We applied LDA, a topic modeling algorithm, to group the text data into 5 topics. Each document was assigned to one of these topics, based on the dominant patterns of words it contained.\n",
        "\n",
        "#### 4. **KMeans Clustering**:\n",
        "   - We clustered the documents into 5 groups using the KMeans clustering algorithm, where each cluster contains documents that are similar to each other in terms of their word features.\n",
        "   - For each cluster, we displayed the top 10 most common words, which provide insights into the main themes of each cluster. For example, Cluster 0 has common terms related to history, while Cluster 1 contains more conversational terms like \"je\" and \"que\".\n",
        "\n",
        "#### 5. **Results and Interpretation**:\n",
        "   - The top terms for each cluster give an indication of the main topics and themes present in the text data.\n",
        "   - These clusters can help in better understanding the underlying structure of the text, identifying common themes, and grouping similar documents together.\n",
        "\n",
        "This step-by-step approach allowed us to clean, process, and extract valuable insights from the text data.\n",
        "\n",
        "Link to data: https://www.kaggle.com/datasets/manueldesiretaira/dataset-for-text-summarization/discussion?sort=hotness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c045e748",
      "metadata": {
        "id": "c045e748"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}