{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vanessa WIlliams"
      ],
      "metadata": {
        "id": "HvgDdwAjtilW"
      },
      "id": "HvgDdwAjtilW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "Bi_fyElg1zDR"
      },
      "id": "Bi_fyElg1zDR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After calling in the libraries needed to run codes, I downnloaded a program within NLTK library to remove common English words, loaded the data to \"clean\". and displaye all of the dataset."
      ],
      "metadata": {
        "id": "POKdkTHovOPe"
      },
      "id": "POKdkTHovOPe"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JKx7X1Ndt-IL"
      },
      "id": "JKx7X1Ndt-IL"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f47ca94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "3f47ca94",
        "outputId": "3efb6f0c-a466-4e20-d56e-99b81368569b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/vanessawilliams/Desktop/Vanessa_Williams/twitter_sample.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-43f95306c46e>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load the dataset from your local folder (replace with the correct path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/vanessawilliams/Desktop/Vanessa_Williams/twitter_sample.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Display the first few rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/vanessawilliams/Desktop/Vanessa_Williams/twitter_sample.csv'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK stopwords if needed\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load the dataset from your local folder (replace with the correct path)\n",
        "file_path = '/Users/vanessawilliams/Desktop/Vanessa_Williams/twitter_sample.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7cc9f8",
      "metadata": {
        "id": "bb7cc9f8"
      },
      "source": [
        "## Clean the Tweet Content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selected the text that I want to clean. To do so, I tokenized the text. This prepares text data for NLP tasks. Then i called a function that removes retweets and display the cleaned data/"
      ],
      "metadata": {
        "id": "sfMWuQz0ws6O"
      },
      "id": "sfMWuQz0ws6O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcaee49b",
      "metadata": {
        "id": "fcaee49b",
        "outputId": "2fd2aadb-6bcc-44ad-9b70-4b6fbe59e3ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet Id</th>\n",
              "      <th>Tweet URL</th>\n",
              "      <th>Tweet Posted Time (UTC)</th>\n",
              "      <th>Tweet Content</th>\n",
              "      <th>Tweet Type</th>\n",
              "      <th>Client</th>\n",
              "      <th>Retweets Received</th>\n",
              "      <th>Likes Received</th>\n",
              "      <th>Tweet Location</th>\n",
              "      <th>Tweet Language</th>\n",
              "      <th>...</th>\n",
              "      <th>Username</th>\n",
              "      <th>User Bio</th>\n",
              "      <th>Verified or Non-Verified</th>\n",
              "      <th>Profile URL</th>\n",
              "      <th>Protected or Non-protected</th>\n",
              "      <th>User Followers</th>\n",
              "      <th>User Following</th>\n",
              "      <th>User Account Creation Date</th>\n",
              "      <th>Impressions</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"1167237977615097861\"</td>\n",
              "      <td>https://twitter.com/lordbyronaf/status/1167237...</td>\n",
              "      <td>8/30/19 0:49</td>\n",
              "      <td>What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...</td>\n",
              "      <td>ReTweet</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Ohio, USA</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>lordbyronaf</td>\n",
              "      <td>It's easier to be who you are, than it is to b...</td>\n",
              "      <td>Non-Verified</td>\n",
              "      <td>https://twitter.com/lordbyronaf</td>\n",
              "      <td>Non-Protected</td>\n",
              "      <td>7808</td>\n",
              "      <td>8617</td>\n",
              "      <td>7/25/12 15:43</td>\n",
              "      <td>0</td>\n",
              "      <td>great team ‚Å¶ ‚Å¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"1167236897078480898\"</td>\n",
              "      <td>https://twitter.com/CountessDavis/status/11672...</td>\n",
              "      <td>8/30/19 0:45</td>\n",
              "      <td>What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...</td>\n",
              "      <td>ReTweet</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>CountessDavis</td>\n",
              "      <td>I am named after @ElvisPresley daughter Lisa M...</td>\n",
              "      <td>Non-Verified</td>\n",
              "      <td>https://twitter.com/CountessDavis</td>\n",
              "      <td>Non-Protected</td>\n",
              "      <td>291</td>\n",
              "      <td>81</td>\n",
              "      <td>1/26/17 18:21</td>\n",
              "      <td>0</td>\n",
              "      <td>great team ‚Å¶ ‚Å¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"1167228378191204353\"</td>\n",
              "      <td>https://twitter.com/Local12/status/11672283781...</td>\n",
              "      <td>8/30/19 0:11</td>\n",
              "      <td>What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...</td>\n",
              "      <td>ReTweet</td>\n",
              "      <td>TweetDeck</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Cincinnati, OH</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>Local12</td>\n",
              "      <td>Local 12 is #Cincinnati's trusted source for b...</td>\n",
              "      <td>Verified</td>\n",
              "      <td>https://twitter.com/Local12</td>\n",
              "      <td>Non-Protected</td>\n",
              "      <td>198675</td>\n",
              "      <td>651</td>\n",
              "      <td>9/2/08 20:09</td>\n",
              "      <td>0</td>\n",
              "      <td>great team ‚Å¶ ‚Å¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"1167228285463531520\"</td>\n",
              "      <td>https://twitter.com/lbonis1/status/11672282854...</td>\n",
              "      <td>8/30/19 0:11</td>\n",
              "      <td>What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...</td>\n",
              "      <td>Tweet</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>WKRC TV</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>lbonis1</td>\n",
              "      <td>Health and Medical Reporter/News Anchor Regist...</td>\n",
              "      <td>Verified</td>\n",
              "      <td>https://twitter.com/lbonis1</td>\n",
              "      <td>Non-Protected</td>\n",
              "      <td>6015</td>\n",
              "      <td>4866</td>\n",
              "      <td>3/16/13 12:05</td>\n",
              "      <td>12033</td>\n",
              "      <td>great team ‚Å¶ ‚Å¶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"1166892836165496835\"</td>\n",
              "      <td>https://twitter.com/AndreaWestbyMD/status/1166...</td>\n",
              "      <td>8/29/19 1:58</td>\n",
              "      <td>Y‚Äôall ‚Å¶@UMNNMFamMedRes‚Å© Rose Marie Leslie is a...</td>\n",
              "      <td>Tweet</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>Minneapolis, MN</td>\n",
              "      <td>English</td>\n",
              "      <td>...</td>\n",
              "      <td>AndreaWestbyMD</td>\n",
              "      <td>She/her/hers. Teacher of family medicine, form...</td>\n",
              "      <td>Non-Verified</td>\n",
              "      <td>https://twitter.com/AndreaWestbyMD</td>\n",
              "      <td>Non-Protected</td>\n",
              "      <td>938</td>\n",
              "      <td>1247</td>\n",
              "      <td>4/15/15 19:58</td>\n",
              "      <td>1876</td>\n",
              "      <td>y‚Äôall ‚Å¶ rose marie leslie ‚Å¶ blue ribbon winnin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Tweet Id                                          Tweet URL   \n",
              "2   \"1167237977615097861\"  https://twitter.com/lordbyronaf/status/1167237...  \\\n",
              "3   \"1167236897078480898\"  https://twitter.com/CountessDavis/status/11672...   \n",
              "4   \"1167228378191204353\"  https://twitter.com/Local12/status/11672283781...   \n",
              "5   \"1167228285463531520\"  https://twitter.com/lbonis1/status/11672282854...   \n",
              "12  \"1166892836165496835\"  https://twitter.com/AndreaWestbyMD/status/1166...   \n",
              "\n",
              "   Tweet Posted Time (UTC)                                      Tweet Content   \n",
              "2             8/30/19 0:49  What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...  \\\n",
              "3             8/30/19 0:45  What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...   \n",
              "4             8/30/19 0:11  What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...   \n",
              "5             8/30/19 0:11  What a great team ‚Å¶@HealthSourceOH‚Å© ‚Å¶@Local12‚Å©...   \n",
              "12            8/29/19 1:58  Y‚Äôall ‚Å¶@UMNNMFamMedRes‚Å© Rose Marie Leslie is a...   \n",
              "\n",
              "   Tweet Type               Client  Retweets Received  Likes Received   \n",
              "2     ReTweet  Twitter for Android                  0               0  \\\n",
              "3     ReTweet  Twitter for Android                  0               0   \n",
              "4     ReTweet            TweetDeck                  0               0   \n",
              "5       Tweet   Twitter for iPhone                  3              17   \n",
              "12      Tweet   Twitter for iPhone                  0              27   \n",
              "\n",
              "     Tweet Location Tweet Language  ...        Username   \n",
              "2         Ohio, USA        English  ...     lordbyronaf  \\\n",
              "3               NaN        English  ...   CountessDavis   \n",
              "4    Cincinnati, OH        English  ...         Local12   \n",
              "5           WKRC TV        English  ...         lbonis1   \n",
              "12  Minneapolis, MN        English  ...  AndreaWestbyMD   \n",
              "\n",
              "                                             User Bio   \n",
              "2   It's easier to be who you are, than it is to b...  \\\n",
              "3   I am named after @ElvisPresley daughter Lisa M...   \n",
              "4   Local 12 is #Cincinnati's trusted source for b...   \n",
              "5   Health and Medical Reporter/News Anchor Regist...   \n",
              "12  She/her/hers. Teacher of family medicine, form...   \n",
              "\n",
              "   Verified or Non-Verified                         Profile URL   \n",
              "2              Non-Verified     https://twitter.com/lordbyronaf  \\\n",
              "3              Non-Verified   https://twitter.com/CountessDavis   \n",
              "4                  Verified         https://twitter.com/Local12   \n",
              "5                  Verified         https://twitter.com/lbonis1   \n",
              "12             Non-Verified  https://twitter.com/AndreaWestbyMD   \n",
              "\n",
              "   Protected or Non-protected User Followers User Following   \n",
              "2               Non-Protected           7808           8617  \\\n",
              "3               Non-Protected            291             81   \n",
              "4               Non-Protected         198675            651   \n",
              "5               Non-Protected           6015           4866   \n",
              "12              Non-Protected            938           1247   \n",
              "\n",
              "    User Account Creation Date  Impressions   \n",
              "2                7/25/12 15:43            0  \\\n",
              "3                1/26/17 18:21            0   \n",
              "4                 9/2/08 20:09            0   \n",
              "5                3/16/13 12:05        12033   \n",
              "12               4/15/15 19:58         1876   \n",
              "\n",
              "                                        cleaned_tweet  \n",
              "2                                      great team ‚Å¶ ‚Å¶  \n",
              "3                                      great team ‚Å¶ ‚Å¶  \n",
              "4                                      great team ‚Å¶ ‚Å¶  \n",
              "5                                      great team ‚Å¶ ‚Å¶  \n",
              "12  y‚Äôall ‚Å¶ rose marie leslie ‚Å¶ blue ribbon winnin...  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clean the \"Tweet Content\" column by removing non-text data and stopwords\n",
        "def clean_text(text):\n",
        "    # RLs, mentioRemove non-text data like Uns, and hashtags\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\S+|#\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize text and remove stopwords\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Join tokens back into a single string\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the cleaning function to the \"Tweet Content\" column\n",
        "df['cleaned_tweet'] = df['Tweet Content'].apply(clean_text)\n",
        "\n",
        "# Filter only tweets (removing retweets)\n",
        "df = df[~df['cleaned_tweet'].str.contains('rt', case=False)]\n",
        "\n",
        "# Display the cleaned data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3632f935",
      "metadata": {
        "id": "3632f935"
      },
      "source": [
        "# Remove Duplicate Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb33e28",
      "metadata": {
        "id": "deb33e28",
        "outputId": "1cf58e6f-50a9-451c-ca47-d6b15df46ecd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cleaned_tweet\n",
              "great team ‚Å¶ ‚Å¶                                                                                                                                          1\n",
              "2 episodes left july favorite past year haven‚Äôt played yet got guess next 2 might days till next one                                                    1\n",
              "weve loved motivated stories social prescribing initiatives around world continue conversations us national conference november well discussing need    1\n",
              "doubt incredible job full challenges beyond rewarding weekends like great reminder work hard love                                                       1\n",
              "agree                                                                                                                                                   1\n",
              "                                                                                                                                                       ..\n",
              "vaccines help prevent illness else protect animals ‚¨áÔ∏è heres solutions                                                                                   1\n",
              "love                                                                                                                                                    1\n",
              "impfen sch√ºtztüíâüêïüêàüêÑüêñüêéüêî der beste weg zu mehr tiergesundheit krankheiten vermeiden lesen sie unsere üì∞pressemitteilung                                     1\n",
              "hope enjoying summer family amp friends bring along stomp 2019 register today annual 6 mile sponsored walk sat 12 oct 2019                              1\n",
              "great weekend back month july rebroadcasting best past year crew takes much needed break transitions new academic year                                  1\n",
              "Name: count, Length: 81, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop duplicate tweets based on the 'cleaned_tweet' column\n",
        "df = df.drop_duplicates(subset='cleaned_tweet', keep='first')\n",
        "\n",
        "# Verify if duplicates were removed\n",
        "df['cleaned_tweet'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e679298c",
      "metadata": {
        "id": "e679298c"
      },
      "source": [
        "# Bag of Words (BoW) Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b535f48",
      "metadata": {
        "id": "7b535f48",
        "outputId": "e9d80383-1ca4-4d70-b15a-56cad30aec4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of Words Representation:\n",
            "    10  10000  12  2010  2019  21  25  40  5000th  600  ...  year  years   \n",
            "0   0      0   0     0     0   0   0   0       0    0  ...     0      0  \\\n",
            "1   0      0   0     0     0   0   0   0       0    0  ...     0      0   \n",
            "2   0      0   0     0     0   0   0   0       0    0  ...     0      0   \n",
            "3   0      0   0     0     0   0   0   0       0    0  ...     0      0   \n",
            "4   0      0   0     0     0   0   0   0       0    0  ...     0      0   \n",
            "\n",
            "   yesterday  yet  young  youre  zoonosen  zu  zwierzƒÖt  ≈ºe  \n",
            "0          0    0      0      0         0   0         0   0  \n",
            "1          0    0      0      0         0   0         0   0  \n",
            "2          0    0      0      0         0   0         0   0  \n",
            "3          0    0      0      0         1   0         0   0  \n",
            "4          0    0      0      0         0   0         2   1  \n",
            "\n",
            "[5 rows x 623 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Bag of Words (BoW) Representation\n",
        "cv = CountVectorizer()\n",
        "cv_matrix = cv.fit_transform(df['cleaned_tweet'])\n",
        "vocab = cv.get_feature_names_out()\n",
        "\n",
        "# Convert the BoW matrix to a DataFrame for better visualization\n",
        "bow_df = pd.DataFrame(cv_matrix.toarray(), columns=vocab)\n",
        "print(\"Bag of Words Representation:\\n\", bow_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d9a47a",
      "metadata": {
        "id": "f5d9a47a"
      },
      "source": [
        "## TF-IDF Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: TF-IDF Representation\n",
        "### Convert the TF-IDF matrix to a DataFrame for better visualization\n",
        "### Display results"
      ],
      "metadata": {
        "id": "Ww0cNisA0Byx"
      },
      "id": "Ww0cNisA0Byx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2de87c",
      "metadata": {
        "id": "fe2de87c",
        "outputId": "ae4c884c-42f8-431d-948a-4b90894d8ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TF-IDF Representation:\n",
            "     10  10000   12  2010  2019   21   25   40  5000th  600  ...  year  years   \n",
            "0  0.0    0.0  0.0   0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...   0.0    0.0  \\\n",
            "1  0.0    0.0  0.0   0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...   0.0    0.0   \n",
            "2  0.0    0.0  0.0   0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...   0.0    0.0   \n",
            "3  0.0    0.0  0.0   0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...   0.0    0.0   \n",
            "4  0.0    0.0  0.0   0.0   0.0  0.0  0.0  0.0     0.0  0.0  ...   0.0    0.0   \n",
            "\n",
            "   yesterday  yet  young  youre  zoonosen   zu  zwierzƒÖt        ≈ºe  \n",
            "0        0.0  0.0    0.0    0.0  0.000000  0.0  0.000000  0.000000  \n",
            "1        0.0  0.0    0.0    0.0  0.000000  0.0  0.000000  0.000000  \n",
            "2        0.0  0.0    0.0    0.0  0.000000  0.0  0.000000  0.000000  \n",
            "3        0.0  0.0    0.0    0.0  0.353553  0.0  0.000000  0.000000  \n",
            "4        0.0  0.0    0.0    0.0  0.000000  0.0  0.460832  0.230416  \n",
            "\n",
            "[5 rows x 623 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 3: TF-IDF Representation\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['cleaned_tweet'])\n",
        "tfidf_vocab = tfidf.get_feature_names_out()\n",
        "\n",
        "# Convert the TF-IDF matrix to a DataFrame for better visualization\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vocab)\n",
        "print(\"\\nTF-IDF Representation:\\n\", tfidf_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd152b60",
      "metadata": {
        "id": "bd152b60"
      },
      "source": [
        "# Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Cosine Similarity between documents (tweets)\n",
        "### Display Results"
      ],
      "metadata": {
        "id": "Rb1njc9C0eDG"
      },
      "id": "Rb1njc9C0eDG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55128eb7",
      "metadata": {
        "id": "55128eb7",
        "outputId": "35d0f32d-3c44-4013-bd83-9def91c10316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cosine Similarity Matrix:\n",
            " [[1.         0.         0.         ... 0.         0.         0.13185464]\n",
            " [0.         1.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         1.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 1.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         1.         0.21101903]\n",
            " [0.13185464 0.         0.         ... 0.         0.21101903 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Cosine Similarity between documents (tweets)\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "print(\"\\nCosine Similarity Matrix:\\n\", cosine_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e45912",
      "metadata": {
        "id": "24e45912"
      },
      "source": [
        "# Find Most Similar Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Find most similar tweets to the first tweet (index 0)\n",
        "### Sort the tweets by similarity in descending order\n",
        "### Display Results\n"
      ],
      "metadata": {
        "id": "b-8W2qwg1EG8"
      },
      "id": "b-8W2qwg1EG8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "274088f3",
      "metadata": {
        "id": "274088f3",
        "outputId": "4158260a-94c3-427d-bb7f-30290d8df232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 most similar tweets to the first tweet:\n",
            "Tweet 0 - Cosine Similarity: 1.0\n",
            "great team ‚Å¶ ‚Å¶ \n",
            "\n",
            "Tweet 10 - Cosine Similarity: 0.2588208505551044\n",
            "delivered 5000th special aflac duck yesterday proud team \n",
            "\n",
            "Tweet 77 - Cosine Similarity: 0.17381648047381992\n",
            "great stats shared french member annual conference 64 new since 2010 \n",
            "\n",
            "Tweet 58 - Cosine Similarity: 0.1537358270295723\n",
            "doubt incredible job full challenges beyond rewarding weekends like great reminder work hard love \n",
            "\n",
            "Tweet 80 - Cosine Similarity: 0.13185463897514438\n",
            "great weekend back month july rebroadcasting best past year crew takes much needed break transitions new academic year \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Find most similar tweets to the first tweet (index 0)\n",
        "similar_tweets = cosine_sim[0]\n",
        "\n",
        "# Sort the tweets by similarity in descending order\n",
        "similar_indices = similar_tweets.argsort()[-5:][::-1]\n",
        "print(\"\\nTop 5 most similar tweets to the first tweet:\")\n",
        "for idx in similar_indices:\n",
        "    print(f\"Tweet {idx} - Cosine Similarity: {similar_tweets[idx]}\")\n",
        "    print(df['cleaned_tweet'].iloc[idx], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aed670b",
      "metadata": {
        "id": "6aed670b"
      },
      "source": [
        "### Summary of Results:\n",
        "\n",
        "The final output shows the top 5 tweets that are most similar to the first tweet in the dataset, based on **Cosine Similarity** using their **TF-IDF representations**.\n",
        "\n",
        "- **Tweet 0** has a **Cosine Similarity of 1.0** because it is being compared to itself.\n",
        "- The other tweets have lower similarity scores, indicating varying levels of similarity to the first tweet:\n",
        "  - **Tweet 10** has a similarity score of **0.2588**, making it the most similar to the first tweet.\n",
        "  - **Tweet 77** and **Tweet 58** also show moderate similarity with scores of **0.1738** and **0.1537** respectively.\n",
        "  - **Tweet 80** has the lowest similarity score in the top 5 at **0.1319**.\n",
        "\n",
        "### Cosine Similarity Explanation:\n",
        "\n",
        "I used Cosine Similarity to measure the similarity between tweets. It compares the **TF-IDF vector representations** of each tweet to calculate the similarity based on the angle between their vectorized representations in multi-dimensional space. A score of **1.0** indicates identical content, while scores closer to **0** indicate less similarity.\n",
        "\n",
        "### Observations:\n",
        "\n",
        "- **Cleaning and pre-processing**: After cleaning the dataset by removing non-text content and duplicates, we observed a more meaningful distribution of similarity scores.\n",
        "- **Variation in similarity**: Without duplicates, tweets that share similar content (such as references to teams, events, or general sentiments) appear as more similar, while tweets with different content show lower similarity scores.\n",
        "- **Insights**: Cosine Similarity was effective in identifying tweets that share similar language and topics, while successfully differentiating between tweets with less content overlap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e51e7cc",
      "metadata": {
        "id": "9e51e7cc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}