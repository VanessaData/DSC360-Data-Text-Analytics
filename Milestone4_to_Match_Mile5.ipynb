{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Vanessa Williams\n",
        "## Milestone 4"
      ],
      "metadata": {
        "id": "ALCXE8GFXuHE"
      },
      "id": "ALCXE8GFXuHE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To complete milestone 5, I needed to change milestone 4"
      ],
      "metadata": {
        "id": "Q3vS1KrXljqv"
      },
      "id": "Q3vS1KrXljqv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9cde9c",
      "metadata": {
        "id": "be9cde9c",
        "outputId": "1e78d4f7-f684-4194-86f1-1404acbb2d76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top terms per cluster:\n",
            "\n",
            "Cluster 0 terms:\n",
            "says          866.627043\n",
            "government    577.079505\n",
            "mr            533.264276\n",
            "new           448.407089\n",
            "united        417.288235\n",
            "year          386.344681\n",
            "country       371.693201\n",
            "states        346.038956\n",
            "world         338.975700\n",
            "minister      335.793206\n",
            "dtype: float64\n",
            "\n",
            "Cluster 1 terms:\n",
            "people      608.489151\n",
            "killed      598.802400\n",
            "wounded     175.191744\n",
            "bomb        115.347962\n",
            "says         99.357957\n",
            "police       92.466762\n",
            "baghdad      92.232516\n",
            "attack       78.390278\n",
            "soldiers     72.636617\n",
            "attacks      66.686702\n",
            "dtype: float64\n",
            "\n",
            "Cluster 2 terms:\n",
            "said          1162.600846\n",
            "mr             150.891640\n",
            "officials      116.717164\n",
            "spokesman       98.297384\n",
            "government      80.903639\n",
            "statement       80.293106\n",
            "tuesday         77.193566\n",
            "military        73.721417\n",
            "friday          72.734315\n",
            "thursday        71.138870\n",
            "dtype: float64\n",
            "\n",
            "Cluster 3 terms:\n",
            "say            922.872401\n",
            "officials      427.230847\n",
            "police         168.580283\n",
            "authorities    148.392320\n",
            "killed          97.293694\n",
            "near            65.003717\n",
            "people          61.435416\n",
            "militants       59.690652\n",
            "security        59.301902\n",
            "witnesses       57.259470\n",
            "dtype: float64\n",
            "\n",
            "Cluster 4 terms:\n",
            "president     817.084418\n",
            "bush          183.801532\n",
            "mr             88.182003\n",
            "said           81.951656\n",
            "says           73.243855\n",
            "chavez         72.475434\n",
            "vice           63.329805\n",
            "minister       63.048339\n",
            "new            61.806566\n",
            "government     56.563699\n",
            "dtype: float64\n",
            "\n",
            "Sample Named Entities extracted:\n",
            "                                            Sentence   \n",
            "0  Thousands of demonstrators have marched throug...  \\\n",
            "1  Families of soldiers killed in the conflict jo...   \n",
            "2  They marched from the Houses of Parliament to ...   \n",
            "3  Police put the number of marchers at 10,000 wh...   \n",
            "4  The protest comes on the eve of the annual con...   \n",
            "5  The party is divided over Britain 's participa...   \n",
            "6  The London march came ahead of anti-war protes...   \n",
            "7  The International Atomic Energy Agency is to h...   \n",
            "8  Iran this week restarted parts of the conversi...   \n",
            "9  Iranian officials say they expect to get acces...   \n",
            "\n",
            "                                            entities  \n",
            "0  [(Thousands, CARDINAL), (London, GPE), (Iraq, ...  \n",
            "1                 [(Stop the Bombings, WORK_OF_ART)]  \n",
            "2  [(the Houses of Parliament, ORG), (Hyde Park, ...  \n",
            "3         [(10,000, CARDINAL), (1,00,000, CARDINAL)]  \n",
            "4  [(the eve, DATE), (annual, DATE), (Britain, GP...  \n",
            "5  [(Britain, GPE), (Iraq, GPE), (8,500, CARDINAL...  \n",
            "6  [(London, GPE), (today, DATE), (Rome, GPE), (P...  \n",
            "7  [(The International Atomic Energy Agency, ORG)...  \n",
            "8   [(Iran, GPE), (this week, DATE), (Isfahan, FAC)]  \n",
            "9  [(Iranian, NORP), (Wednesday, DATE), (IAEA, ORG)]  \n",
            "\n",
            "Euclidean Distance between first two sentences: 1.4142135623730951\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Load NLTK stopwords and specify custom path\n",
        "nltk.data.path.append(\"/Users/vanessawilliams/nltk_data\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/Users/vanessawilliams/Desktop/Vanessa_Williams/ner.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Clean the text as done in Milestone 3\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "data['cleaned_text'] = data['Sentence'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(data['cleaned_text'])\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "# Step 1: Clustering with KMeans\n",
        "kmeans = KMeans(n_clusters=5, random_state=0)\n",
        "data['cluster'] = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "# Display top terms per cluster\n",
        "print(\"Top terms per cluster:\")\n",
        "for i in range(5):\n",
        "    cluster_terms = tfidf_df[data['cluster'] == i].sum().sort_values(ascending=False).head(10)\n",
        "    print(f\"\\nCluster {i} terms:\\n{cluster_terms}\")\n",
        "\n",
        "# Step 2: Named Entity Recognition (NER) with spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "data['entities'] = data['Sentence'].apply(extract_entities)\n",
        "\n",
        "# Display sample NER results\n",
        "print(\"\\nSample Named Entities extracted:\")\n",
        "print(data[['Sentence', 'entities']].head(10))\n",
        "\n",
        "# Step 3: Text Similarity with Euclidean Distance\n",
        "sample_distance = euclidean_distances(tfidf_matrix[0], tfidf_matrix[1])\n",
        "print(f\"\\nEuclidean Distance between first two sentences: {sample_distance[0][0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1472f4f5",
      "metadata": {
        "id": "1472f4f5"
      },
      "source": [
        "## Milestone 4: Building and Exploring the Text Model\n",
        "\n",
        "### Objective\n",
        "In Milestone 4, the goal was to build an initial model to explore the structure and themes in our text data. This involved identifying clusters or themes within the data and performing Named Entity Recognition (NER) to extract key entities. The goal was to develop insights into the topics covered in the dataset and identify the primary entities mentioned.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "1. **Data Preprocessing**:\n",
        "   - We cleaned the text by removing non-alphabetic characters, converting text to lowercase, and removing stopwords using NLTK's stopword list.\n",
        "   - After cleaning, we applied TF-IDF vectorization to transform the text into a matrix of features, retaining the top 1,000 terms for analysis.\n",
        "\n",
        "2. **KMeans Clustering**:\n",
        "   - We performed KMeans clustering on the TF-IDF matrix with 5 clusters to group similar sentences.\n",
        "   - This clustering helped us identify common themes by examining the most significant terms within each cluster.\n",
        "\n",
        "3. **Named Entity Recognition (NER)**:\n",
        "   - Using the `en_core_web_sm` model from spaCy, we conducted Named Entity Recognition on each sentence.\n",
        "   - This step allowed us to extract entities such as people, locations, and organizations, giving more insight into the main subjects discussed in the text.\n",
        "\n",
        "### Results\n",
        "\n",
        "#### Clustering Analysis\n",
        "Each cluster represents a distinct topic or theme in the data. Below are the top terms for each cluster and the themes they suggest:\n",
        "\n",
        "- **Cluster 0**: Focuses on government-related topics, with terms like \"government,\" \"minister,\" \"united,\" and \"country,\" indicating discussions about governance, political leaders, and international relations.\n",
        "- **Cluster 1**: Relates to conflict or violence, with terms like \"people,\" \"killed,\" \"bomb,\" and \"police.\" This suggests the presence of reports on attacks or incidents involving casualties.\n",
        "- **Cluster 2**: Highlights statements and official reports, with words like \"said,\" \"officials,\" \"spokesman,\" and \"statement,\" likely representing press releases or official announcements.\n",
        "- **Cluster 3**: Focuses on law enforcement and security, with terms like \"officials,\" \"police,\" \"authorities,\" and \"security,\" pointing to news about public safety and authority responses.\n",
        "- **Cluster 4**: Centers on leadership and political figures, with frequent mentions of \"president,\" \"bush,\" \"chavez,\" and \"minister.\" This cluster seems to involve discussions around political leaders and events related to them.\n",
        "\n",
        "#### Named Entity Recognition (NER)\n",
        "By performing NER, we extracted entities such as names of people, locations, and organizations. This provides additional context for each cluster. For example:\n",
        "- **Cluster 0** often includes countries or government entities, while **Cluster 4** prominently features political figures like \"president\" and specific names.\n",
        "- This information will help us analyze trends related to particular entities and topics, adding depth to our understanding of the dataset.\n",
        "\n",
        "### Observations and Interpretation\n",
        "\n",
        "- **Cluster Analysis**: The clusters align well with recognizable themes in the text. This indicates that the data contains distinguishable topics, allowing us to interpret the dataset based on these key themes.\n",
        "- **Entity Extraction**: The entities extracted through NER offer insight into the specific people, places, and organizations that appear frequently. This allows us to understand which entities are central to each theme, enhancing the analysis of cluster content.\n",
        "- **Text Structure**: The combination of clustering and NER demonstrates that the text data is structured around key topics with distinct themes and notable entities, setting a solid foundation for further analysis.\n",
        "\n",
        "### Conclusion\n",
        "In Milestone 4, we successfully created an initial model that clusters the text data into themes and performs Named Entity Recognition. These steps provide a comprehensive view of the text’s structure, key topics, and primary entities. This exploratory analysis serves as a foundation for building more complex models and performing detailed topic or entity-focused analysis in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfa6875",
      "metadata": {
        "id": "cbfa6875"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}