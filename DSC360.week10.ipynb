{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vanessa Williams\n",
        "# Week 10"
      ],
      "metadata": {
        "id": "TjAqJ0dGNLCf"
      },
      "id": "TjAqJ0dGNLCf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f1378f",
      "metadata": {
        "id": "35f1378f",
        "outputId": "7b351673-3be8-42e0-d2fb-cea25ec32b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 50ms/step - accuracy: 0.7700 - loss: 0.4782 - val_accuracy: 0.8645 - val_loss: 0.3323\n",
            "Epoch 2/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 48ms/step - accuracy: 0.8855 - loss: 0.2872 - val_accuracy: 0.8655 - val_loss: 0.3244\n",
            "Epoch 3/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.9090 - loss: 0.2359 - val_accuracy: 0.8619 - val_loss: 0.3489\n",
            "Epoch 4/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 49ms/step - accuracy: 0.9274 - loss: 0.1906 - val_accuracy: 0.8551 - val_loss: 0.3695\n",
            "Epoch 5/5\n",
            "\u001b[1m487/487\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 49ms/step - accuracy: 0.9396 - loss: 0.1668 - val_accuracy: 0.8504 - val_loss: 0.3917\n",
            "\u001b[1m244/244\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8481 - loss: 0.4046\n",
            "Test Accuracy: 0.8504\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "Predictions on sample test data: [[0.00186571]\n",
            " [0.01494121]\n",
            " [0.00549844]\n",
            " [0.07874314]\n",
            " [0.9968305 ]\n",
            " [0.01350441]\n",
            " [0.0225072 ]\n",
            " [0.9495043 ]\n",
            " [0.05051925]\n",
            " [0.05260415]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/Users/vanessawilliams/Desktop/Vanessa_Williams/hotel_reviews.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Preprocessing: Use 'Description' column for reviews and encode 'Is_Response' column\n",
        "data['Is_Response'] = data['Is_Response'].apply(lambda x: 1 if x == 'not happy' else 0)\n",
        "reviews = data['Description'].values  # Updated to 'Description'\n",
        "labels = data['Is_Response'].values\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100)\n",
        "\n",
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model definition\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
        "    layers.LSTM(64, return_sequences=True),\n",
        "    layers.LSTM(32),\n",
        "    layers.Dense(24, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions (optional)\n",
        "predictions = model.predict(X_test[:10])\n",
        "print(\"Predictions on sample test data:\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yUzgQU81NB_r"
      },
      "id": "yUzgQU81NB_r"
    },
    {
      "cell_type": "markdown",
      "id": "c97d853f",
      "metadata": {
        "id": "c97d853f"
      },
      "source": [
        "# Sentiment Analysis on Hotel Reviews\n",
        "\n",
        "## Project Overview\n",
        "In this assignment, we performed sentiment analysis on hotel reviews to classify them as either \"happy\" or \"not happy.\" We utilized a neural network built with TensorFlow and Keras for this binary classification task.\n",
        "\n",
        "## Steps and Approach\n",
        "\n",
        "### 1. Data Preparation\n",
        "- We loaded the dataset from the specified CSV file.\n",
        "- The reviews were stored in the `Description` column, and the labels (`Is_Response`) indicated sentiment, with \"not happy\" reviews labeled as `1` and \"happy\" reviews labeled as `0`.\n",
        "\n",
        "### 2. Text Preprocessing\n",
        "- We tokenized the text data using Keras’s `Tokenizer`, limited to 10,000 words and a maximum sequence length of 100.\n",
        "- The text was converted into sequences of integers, with padding applied to ensure uniform sequence lengths.\n",
        "\n",
        "### 3. Model Building\n",
        "- We built a Sequential neural network model with:\n",
        "  - An Embedding layer to convert words into dense vector representations.\n",
        "  - Two LSTM layers to capture sequential dependencies.\n",
        "  - A Dense layer with ReLU activation for feature extraction.\n",
        "  - A final Dense layer with sigmoid activation for binary classification.\n",
        "- We compiled the model using binary cross-entropy loss and the Adam optimizer.\n",
        "\n",
        "### 4. Training and Evaluation\n",
        "- The model was trained for 5 epochs, achieving an accuracy of approximately **93.96%** on the training data.\n",
        "- On the test data, the model reached a validation accuracy of **85.04%** with a final loss of **0.4046**.\n",
        "\n",
        "### 5. Prediction\n",
        "- We generated predictions on a sample subset of the test data to observe the model’s output. Each prediction indicates the probability that a review is \"not happy.\"\n",
        "\n",
        "## Summary of Results\n",
        "- **Final Test Accuracy**: 85.04%\n",
        "- **Model Performance**: The model showed strong performance, with high accuracy on both training and validation datasets.\n",
        "- **Sample Predictions**: The predicted probabilities illustrate the model's ability to distinguish between \"happy\" and \"not happy\" sentiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8eb04d",
      "metadata": {
        "id": "9c8eb04d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}